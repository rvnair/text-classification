Resetting modules to system default. Reseting $MODULEPATH back to system default. All extra directories will be removed from $MODULEPATH.

Lmod is automatically replacing "python2/2.7.16" with "python3/3.7.0".

using bert tokens
using bert tokens
using bert tokens
Epoch: 1 | Batch: 0/40000 (0%) | Loss: 0.758525
Epoch: 1 | Batch: 160/40000 (0%) | Loss: 0.647283
Epoch: 1 | Batch: 320/40000 (1%) | Loss: 0.675451
Epoch: 1 | Batch: 480/40000 (1%) | Loss: 0.671928
Epoch: 1 | Batch: 640/40000 (2%) | Loss: 0.354610
Epoch: 1 | Batch: 800/40000 (2%) | Loss: 0.495180
Epoch: 1 | Batch: 960/40000 (2%) | Loss: 0.444423
Epoch: 1 | Batch: 1120/40000 (3%) | Loss: 0.477970
Epoch: 1 | Batch: 1280/40000 (3%) | Loss: 0.470166
Epoch: 1 | Batch: 1440/40000 (4%) | Loss: 0.368607
Epoch: 1 | Batch: 1600/40000 (4%) | Loss: 0.365189
Epoch: 1 | Batch: 1760/40000 (4%) | Loss: 0.405609
Epoch: 1 | Batch: 1920/40000 (5%) | Loss: 0.463877
Epoch: 1 | Batch: 2080/40000 (5%) | Loss: 0.379464
Epoch: 1 | Batch: 2240/40000 (6%) | Loss: 0.579999
Epoch: 1 | Batch: 2400/40000 (6%) | Loss: 0.538398
Epoch: 1 | Batch: 2560/40000 (6%) | Loss: 0.351678
Epoch: 1 | Batch: 2720/40000 (7%) | Loss: 0.371487
Epoch: 1 | Batch: 2880/40000 (7%) | Loss: 0.552971
Epoch: 1 | Batch: 3040/40000 (8%) | Loss: 0.371195
Epoch: 1 | Batch: 3200/40000 (8%) | Loss: 0.173984
Epoch: 1 | Batch: 3360/40000 (8%) | Loss: 0.515828
Epoch: 1 | Batch: 3520/40000 (9%) | Loss: 0.611125
Epoch: 1 | Batch: 3680/40000 (9%) | Loss: 0.552805
Epoch: 1 | Batch: 3840/40000 (10%) | Loss: 0.627393
Epoch: 1 | Batch: 4000/40000 (10%) | Loss: 0.396818
Epoch: 1 | Batch: 4160/40000 (10%) | Loss: 0.467824
Epoch: 1 | Batch: 4320/40000 (11%) | Loss: 0.208140
Epoch: 1 | Batch: 4480/40000 (11%) | Loss: 0.518176
Epoch: 1 | Batch: 4640/40000 (12%) | Loss: 0.646355
Epoch: 1 | Batch: 4800/40000 (12%) | Loss: 0.473873
Epoch: 1 | Batch: 4960/40000 (12%) | Loss: 0.621076
Epoch: 1 | Batch: 5120/40000 (13%) | Loss: 0.443676
Epoch: 1 | Batch: 5280/40000 (13%) | Loss: 0.286031
Epoch: 1 | Batch: 5440/40000 (14%) | Loss: 0.347460
Epoch: 1 | Batch: 5600/40000 (14%) | Loss: 0.282729
Epoch: 1 | Batch: 5760/40000 (14%) | Loss: 0.530688
Epoch: 1 | Batch: 5920/40000 (15%) | Loss: 0.554818
Epoch: 1 | Batch: 6080/40000 (15%) | Loss: 0.297438
Epoch: 1 | Batch: 6240/40000 (16%) | Loss: 0.445116
Epoch: 1 | Batch: 6400/40000 (16%) | Loss: 0.161906
Epoch: 1 | Batch: 6560/40000 (16%) | Loss: 0.462336
Epoch: 1 | Batch: 6720/40000 (17%) | Loss: 0.343053
Epoch: 1 | Batch: 6880/40000 (17%) | Loss: 0.450346
Epoch: 1 | Batch: 7040/40000 (18%) | Loss: 0.376245
Epoch: 1 | Batch: 7200/40000 (18%) | Loss: 0.284469
Epoch: 1 | Batch: 7360/40000 (18%) | Loss: 0.598205
Epoch: 1 | Batch: 7520/40000 (19%) | Loss: 0.436057
Epoch: 1 | Batch: 7680/40000 (19%) | Loss: 0.340296
Epoch: 1 | Batch: 7840/40000 (20%) | Loss: 0.401358
Epoch: 1 | Batch: 8000/40000 (20%) | Loss: 0.661234
Epoch: 1 | Batch: 8160/40000 (20%) | Loss: 0.414946
Epoch: 1 | Batch: 8320/40000 (21%) | Loss: 0.245453
Epoch: 1 | Batch: 8480/40000 (21%) | Loss: 0.329179
Epoch: 1 | Batch: 8640/40000 (22%) | Loss: 0.219001
Epoch: 1 | Batch: 8800/40000 (22%) | Loss: 0.590189
Epoch: 1 | Batch: 8960/40000 (22%) | Loss: 0.492370
Epoch: 1 | Batch: 9120/40000 (23%) | Loss: 0.187043
Epoch: 1 | Batch: 9280/40000 (23%) | Loss: 0.292974
Epoch: 1 | Batch: 9440/40000 (24%) | Loss: 0.260723
Epoch: 1 | Batch: 9600/40000 (24%) | Loss: 0.499375
Epoch: 1 | Batch: 9760/40000 (24%) | Loss: 0.211379
Epoch: 1 | Batch: 9920/40000 (25%) | Loss: 0.274865
Epoch: 1 | Batch: 10080/40000 (25%) | Loss: 0.691526
Epoch: 1 | Batch: 10240/40000 (26%) | Loss: 0.459707
Epoch: 1 | Batch: 10400/40000 (26%) | Loss: 0.422382
Epoch: 1 | Batch: 10560/40000 (26%) | Loss: 0.328268
Epoch: 1 | Batch: 10720/40000 (27%) | Loss: 0.487440
Epoch: 1 | Batch: 10880/40000 (27%) | Loss: 0.181916
Epoch: 1 | Batch: 11040/40000 (28%) | Loss: 0.238378
Epoch: 1 | Batch: 11200/40000 (28%) | Loss: 0.353162
Epoch: 1 | Batch: 11360/40000 (28%) | Loss: 0.306982
Epoch: 1 | Batch: 11520/40000 (29%) | Loss: 0.395243
Epoch: 1 | Batch: 11680/40000 (29%) | Loss: 0.413145
Epoch: 1 | Batch: 11840/40000 (30%) | Loss: 0.365361
Epoch: 1 | Batch: 12000/40000 (30%) | Loss: 0.244204
Epoch: 1 | Batch: 12160/40000 (30%) | Loss: 0.368871
Epoch: 1 | Batch: 12320/40000 (31%) | Loss: 0.487124
Epoch: 1 | Batch: 12480/40000 (31%) | Loss: 0.243196
Epoch: 1 | Batch: 12640/40000 (32%) | Loss: 0.381882
Epoch: 1 | Batch: 12800/40000 (32%) | Loss: 0.603753
Epoch: 1 | Batch: 12960/40000 (32%) | Loss: 0.274964
Epoch: 1 | Batch: 13120/40000 (33%) | Loss: 0.789504
Epoch: 1 | Batch: 13280/40000 (33%) | Loss: 0.222633
Epoch: 1 | Batch: 13440/40000 (34%) | Loss: 0.351289
Epoch: 1 | Batch: 13600/40000 (34%) | Loss: 0.365268
Epoch: 1 | Batch: 13760/40000 (34%) | Loss: 0.423580
Epoch: 1 | Batch: 13920/40000 (35%) | Loss: 0.181450
Epoch: 1 | Batch: 14080/40000 (35%) | Loss: 0.204013
Epoch: 1 | Batch: 14240/40000 (36%) | Loss: 0.288087
Epoch: 1 | Batch: 14400/40000 (36%) | Loss: 0.375553
Epoch: 1 | Batch: 14560/40000 (36%) | Loss: 0.599576
Epoch: 1 | Batch: 14720/40000 (37%) | Loss: 0.337055
Epoch: 1 | Batch: 14880/40000 (37%) | Loss: 0.275393
Epoch: 1 | Batch: 15040/40000 (38%) | Loss: 0.177368
Epoch: 1 | Batch: 15200/40000 (38%) | Loss: 0.426182
Epoch: 1 | Batch: 15360/40000 (38%) | Loss: 0.546168
Epoch: 1 | Batch: 15520/40000 (39%) | Loss: 0.510881
Epoch: 1 | Batch: 15680/40000 (39%) | Loss: 0.420380
Epoch: 1 | Batch: 15840/40000 (40%) | Loss: 0.264416
Epoch: 1 | Batch: 16000/40000 (40%) | Loss: 0.873895
Epoch: 1 | Batch: 16160/40000 (40%) | Loss: 0.482387
Epoch: 1 | Batch: 16320/40000 (41%) | Loss: 0.529406
Epoch: 1 | Batch: 16480/40000 (41%) | Loss: 0.714467
Epoch: 1 | Batch: 16640/40000 (42%) | Loss: 0.235959
Epoch: 1 | Batch: 16800/40000 (42%) | Loss: 0.403108
Epoch: 1 | Batch: 16960/40000 (42%) | Loss: 0.450729
Epoch: 1 | Batch: 17120/40000 (43%) | Loss: 0.259734
Epoch: 1 | Batch: 17280/40000 (43%) | Loss: 0.446204
Epoch: 1 | Batch: 17440/40000 (44%) | Loss: 0.395117
Epoch: 1 | Batch: 17600/40000 (44%) | Loss: 0.452138
Epoch: 1 | Batch: 17760/40000 (44%) | Loss: 0.385403
Epoch: 1 | Batch: 17920/40000 (45%) | Loss: 0.723941
Epoch: 1 | Batch: 18080/40000 (45%) | Loss: 0.192715
Epoch: 1 | Batch: 18240/40000 (46%) | Loss: 0.310986
Epoch: 1 | Batch: 18400/40000 (46%) | Loss: 0.593988
Epoch: 1 | Batch: 18560/40000 (46%) | Loss: 0.278184
Epoch: 1 | Batch: 18720/40000 (47%) | Loss: 0.235576
Epoch: 1 | Batch: 18880/40000 (47%) | Loss: 0.352743
Epoch: 1 | Batch: 19040/40000 (48%) | Loss: 0.139190
Epoch: 1 | Batch: 19200/40000 (48%) | Loss: 0.332775
Epoch: 1 | Batch: 19360/40000 (48%) | Loss: 0.180271
Epoch: 1 | Batch: 19520/40000 (49%) | Loss: 0.769386
Epoch: 1 | Batch: 19680/40000 (49%) | Loss: 0.277266
Epoch: 1 | Batch: 19840/40000 (50%) | Loss: 0.645502
Epoch: 1 | Batch: 20000/40000 (50%) | Loss: 0.374029
Epoch: 1 | Batch: 20160/40000 (50%) | Loss: 0.678150
Epoch: 1 | Batch: 20320/40000 (51%) | Loss: 0.306825
Epoch: 1 | Batch: 20480/40000 (51%) | Loss: 0.211334
Epoch: 1 | Batch: 20640/40000 (52%) | Loss: 0.370055
Epoch: 1 | Batch: 20800/40000 (52%) | Loss: 0.412517
Epoch: 1 | Batch: 20960/40000 (52%) | Loss: 0.504952
Epoch: 1 | Batch: 21120/40000 (53%) | Loss: 0.223328
Epoch: 1 | Batch: 21280/40000 (53%) | Loss: 0.662206
Epoch: 1 | Batch: 21440/40000 (54%) | Loss: 0.398656
Epoch: 1 | Batch: 21600/40000 (54%) | Loss: 0.229021
Epoch: 1 | Batch: 21760/40000 (54%) | Loss: 0.424509
Epoch: 1 | Batch: 21920/40000 (55%) | Loss: 0.403596
Epoch: 1 | Batch: 22080/40000 (55%) | Loss: 0.213385
Epoch: 1 | Batch: 22240/40000 (56%) | Loss: 0.394824
Epoch: 1 | Batch: 22400/40000 (56%) | Loss: 0.606481
Epoch: 1 | Batch: 22560/40000 (56%) | Loss: 0.370764
Epoch: 1 | Batch: 22720/40000 (57%) | Loss: 0.565752
Epoch: 1 | Batch: 22880/40000 (57%) | Loss: 0.506964
Epoch: 1 | Batch: 23040/40000 (58%) | Loss: 0.784337
Epoch: 1 | Batch: 23200/40000 (58%) | Loss: 0.604004
Epoch: 1 | Batch: 23360/40000 (58%) | Loss: 0.541452
Epoch: 1 | Batch: 23520/40000 (59%) | Loss: 0.187163
Epoch: 1 | Batch: 23680/40000 (59%) | Loss: 0.156672
Epoch: 1 | Batch: 23840/40000 (60%) | Loss: 0.479300
Epoch: 1 | Batch: 24000/40000 (60%) | Loss: 0.364629
Epoch: 1 | Batch: 24160/40000 (60%) | Loss: 0.332270
Epoch: 1 | Batch: 24320/40000 (61%) | Loss: 0.235219
Epoch: 1 | Batch: 24480/40000 (61%) | Loss: 0.547485
Epoch: 1 | Batch: 24640/40000 (62%) | Loss: 0.375281
Epoch: 1 | Batch: 24800/40000 (62%) | Loss: 0.346478
Epoch: 1 | Batch: 24960/40000 (62%) | Loss: 0.242346
Epoch: 1 | Batch: 25120/40000 (63%) | Loss: 0.470836
Epoch: 1 | Batch: 25280/40000 (63%) | Loss: 0.351789
Epoch: 1 | Batch: 25440/40000 (64%) | Loss: 0.376791
Epoch: 1 | Batch: 25600/40000 (64%) | Loss: 0.267085
Epoch: 1 | Batch: 25760/40000 (64%) | Loss: 0.353396
Epoch: 1 | Batch: 25920/40000 (65%) | Loss: 0.253441
Epoch: 1 | Batch: 26080/40000 (65%) | Loss: 0.345365
Epoch: 1 | Batch: 26240/40000 (66%) | Loss: 0.117694
Epoch: 1 | Batch: 26400/40000 (66%) | Loss: 0.756497
Epoch: 1 | Batch: 26560/40000 (66%) | Loss: 0.294357
Epoch: 1 | Batch: 26720/40000 (67%) | Loss: 0.243472
Epoch: 1 | Batch: 26880/40000 (67%) | Loss: 0.440130
Epoch: 1 | Batch: 27040/40000 (68%) | Loss: 0.198622
Epoch: 1 | Batch: 27200/40000 (68%) | Loss: 0.345963
Epoch: 1 | Batch: 27360/40000 (68%) | Loss: 0.182600
Epoch: 1 | Batch: 27520/40000 (69%) | Loss: 0.234662
Epoch: 1 | Batch: 27680/40000 (69%) | Loss: 0.540944
Epoch: 1 | Batch: 27840/40000 (70%) | Loss: 0.371119
Epoch: 1 | Batch: 28000/40000 (70%) | Loss: 0.484277
Epoch: 1 | Batch: 28160/40000 (70%) | Loss: 0.412190
Epoch: 1 | Batch: 28320/40000 (71%) | Loss: 0.255151
Epoch: 1 | Batch: 28480/40000 (71%) | Loss: 0.358320
Epoch: 1 | Batch: 28640/40000 (72%) | Loss: 0.481411
Epoch: 1 | Batch: 28800/40000 (72%) | Loss: 0.385591
Epoch: 1 | Batch: 28960/40000 (72%) | Loss: 0.314239
Epoch: 1 | Batch: 29120/40000 (73%) | Loss: 0.215662
Epoch: 1 | Batch: 29280/40000 (73%) | Loss: 0.681004
Epoch: 1 | Batch: 29440/40000 (74%) | Loss: 0.456826
Epoch: 1 | Batch: 29600/40000 (74%) | Loss: 0.439606
Epoch: 1 | Batch: 29760/40000 (74%) | Loss: 0.631097
Epoch: 1 | Batch: 29920/40000 (75%) | Loss: 0.526130
Epoch: 1 | Batch: 30080/40000 (75%) | Loss: 0.278527
Epoch: 1 | Batch: 30240/40000 (76%) | Loss: 0.325388
Epoch: 1 | Batch: 30400/40000 (76%) | Loss: 0.330249
Epoch: 1 | Batch: 30560/40000 (76%) | Loss: 0.458254
Epoch: 1 | Batch: 30720/40000 (77%) | Loss: 0.432249
Epoch: 1 | Batch: 30880/40000 (77%) | Loss: 0.378385
Epoch: 1 | Batch: 31040/40000 (78%) | Loss: 0.485503
Epoch: 1 | Batch: 31200/40000 (78%) | Loss: 0.175662
Epoch: 1 | Batch: 31360/40000 (78%) | Loss: 0.223115
Epoch: 1 | Batch: 31520/40000 (79%) | Loss: 0.301125
Epoch: 1 | Batch: 31680/40000 (79%) | Loss: 0.392300
Epoch: 1 | Batch: 31840/40000 (80%) | Loss: 0.325948
Epoch: 1 | Batch: 32000/40000 (80%) | Loss: 0.295248
Epoch: 1 | Batch: 32160/40000 (80%) | Loss: 0.294570
Epoch: 1 | Batch: 32320/40000 (81%) | Loss: 0.290902
Epoch: 1 | Batch: 32480/40000 (81%) | Loss: 0.399747
Epoch: 1 | Batch: 32640/40000 (82%) | Loss: 0.628497
Epoch: 1 | Batch: 32800/40000 (82%) | Loss: 0.346165
Epoch: 1 | Batch: 32960/40000 (82%) | Loss: 0.201432
Epoch: 1 | Batch: 33120/40000 (83%) | Loss: 0.561834
Epoch: 1 | Batch: 33280/40000 (83%) | Loss: 0.449946
Epoch: 1 | Batch: 33440/40000 (84%) | Loss: 0.384159
Epoch: 1 | Batch: 33600/40000 (84%) | Loss: 0.441995
Epoch: 1 | Batch: 33760/40000 (84%) | Loss: 0.309027
Epoch: 1 | Batch: 33920/40000 (85%) | Loss: 0.164314
Epoch: 1 | Batch: 34080/40000 (85%) | Loss: 0.392623
Epoch: 1 | Batch: 34240/40000 (86%) | Loss: 0.452331
Epoch: 1 | Batch: 34400/40000 (86%) | Loss: 0.351769
Epoch: 1 | Batch: 34560/40000 (86%) | Loss: 0.205720
Epoch: 1 | Batch: 34720/40000 (87%) | Loss: 0.472481
Epoch: 1 | Batch: 34880/40000 (87%) | Loss: 0.603786
Epoch: 1 | Batch: 35040/40000 (88%) | Loss: 0.303402
Epoch: 1 | Batch: 35200/40000 (88%) | Loss: 0.501366
Epoch: 1 | Batch: 35360/40000 (88%) | Loss: 0.419451
Epoch: 1 | Batch: 35520/40000 (89%) | Loss: 0.407634
Epoch: 1 | Batch: 35680/40000 (89%) | Loss: 0.146911
Epoch: 1 | Batch: 35840/40000 (90%) | Loss: 0.501445
Epoch: 1 | Batch: 36000/40000 (90%) | Loss: 0.301121
Epoch: 1 | Batch: 36160/40000 (90%) | Loss: 0.176737
Epoch: 1 | Batch: 36320/40000 (91%) | Loss: 0.211737
Epoch: 1 | Batch: 36480/40000 (91%) | Loss: 0.362388
Epoch: 1 | Batch: 36640/40000 (92%) | Loss: 0.562887
Epoch: 1 | Batch: 36800/40000 (92%) | Loss: 0.320382
Epoch: 1 | Batch: 36960/40000 (92%) | Loss: 0.252022
Epoch: 1 | Batch: 37120/40000 (93%) | Loss: 0.397316
Epoch: 1 | Batch: 37280/40000 (93%) | Loss: 0.353918
Epoch: 1 | Batch: 37440/40000 (94%) | Loss: 0.456594
Epoch: 1 | Batch: 37600/40000 (94%) | Loss: 0.219349
Epoch: 1 | Batch: 37760/40000 (94%) | Loss: 0.254857
Epoch: 1 | Batch: 37920/40000 (95%) | Loss: 0.366875
Epoch: 1 | Batch: 38080/40000 (95%) | Loss: 0.725818
Epoch: 1 | Batch: 38240/40000 (96%) | Loss: 0.582492
Epoch: 1 | Batch: 38400/40000 (96%) | Loss: 0.507315
Epoch: 1 | Batch: 38560/40000 (96%) | Loss: 0.405658
Epoch: 1 | Batch: 38720/40000 (97%) | Loss: 0.608041
Epoch: 1 | Batch: 38880/40000 (97%) | Loss: 0.487668
Epoch: 1 | Batch: 39040/40000 (98%) | Loss: 0.359727
Epoch: 1 | Batch: 39200/40000 (98%) | Loss: 0.471844
Epoch: 1 | Batch: 39360/40000 (98%) | Loss: 0.370687
Epoch: 1 | Batch: 39520/40000 (99%) | Loss: 0.564501
Epoch: 1 | Batch: 39680/40000 (99%) | Loss: 0.290229
Epoch: 1 | Batch: 39840/40000 (100%) | Loss: 0.272046
* (Train) Epoch: 1 | Loss: 0.4045
Epoch: 1 | Batch: 0/5000 (0%) | Loss: 0.700860
Epoch: 1 | Batch: 160/5000 (3%) | Loss: 0.357915
Epoch: 1 | Batch: 320/5000 (6%) | Loss: 0.369274
Epoch: 1 | Batch: 480/5000 (10%) | Loss: 0.436412
Epoch: 1 | Batch: 640/5000 (13%) | Loss: 0.598877
Epoch: 1 | Batch: 800/5000 (16%) | Loss: 0.422735
Epoch: 1 | Batch: 960/5000 (19%) | Loss: 0.258000
Epoch: 1 | Batch: 1120/5000 (22%) | Loss: 0.209258
Epoch: 1 | Batch: 1280/5000 (26%) | Loss: 0.354446
Epoch: 1 | Batch: 1440/5000 (29%) | Loss: 0.455780
Epoch: 1 | Batch: 1600/5000 (32%) | Loss: 0.173872
Epoch: 1 | Batch: 1760/5000 (35%) | Loss: 0.496619
Epoch: 1 | Batch: 1920/5000 (38%) | Loss: 0.212988
Epoch: 1 | Batch: 2080/5000 (42%) | Loss: 0.219437
Epoch: 1 | Batch: 2240/5000 (45%) | Loss: 0.271771
Epoch: 1 | Batch: 2400/5000 (48%) | Loss: 0.513399
Epoch: 1 | Batch: 2560/5000 (51%) | Loss: 0.408361
Epoch: 1 | Batch: 2720/5000 (54%) | Loss: 0.425929
Epoch: 1 | Batch: 2880/5000 (58%) | Loss: 0.192822
Epoch: 1 | Batch: 3040/5000 (61%) | Loss: 0.323646
Epoch: 1 | Batch: 3200/5000 (64%) | Loss: 0.307396
Epoch: 1 | Batch: 3360/5000 (67%) | Loss: 0.229435
Epoch: 1 | Batch: 3520/5000 (70%) | Loss: 0.392623
Epoch: 1 | Batch: 3680/5000 (74%) | Loss: 0.328689
Epoch: 1 | Batch: 3840/5000 (77%) | Loss: 0.565810
Epoch: 1 | Batch: 4000/5000 (80%) | Loss: 0.800508
Epoch: 1 | Batch: 4160/5000 (83%) | Loss: 0.340142
Epoch: 1 | Batch: 4320/5000 (86%) | Loss: 0.249291
Epoch: 1 | Batch: 4480/5000 (90%) | Loss: 0.403774
Epoch: 1 | Batch: 4640/5000 (93%) | Loss: 0.326998
Epoch: 1 | Batch: 4800/5000 (96%) | Loss: 0.462508
Epoch: 1 | Batch: 4960/5000 (99%) | Loss: 0.343975
* (Validation) Epoch: 1 | Loss: 0.3635
* Saved
Epoch: 2 | Batch: 0/40000 (0%) | Loss: 0.291129
Epoch: 2 | Batch: 160/40000 (0%) | Loss: 0.132667
Epoch: 2 | Batch: 320/40000 (1%) | Loss: 0.181663
Epoch: 2 | Batch: 480/40000 (1%) | Loss: 0.199512
Epoch: 2 | Batch: 640/40000 (2%) | Loss: 0.237156
Epoch: 2 | Batch: 800/40000 (2%) | Loss: 0.129095
Epoch: 2 | Batch: 960/40000 (2%) | Loss: 0.251261
Epoch: 2 | Batch: 1120/40000 (3%) | Loss: 0.510829
Epoch: 2 | Batch: 1280/40000 (3%) | Loss: 0.422899
Epoch: 2 | Batch: 1440/40000 (4%) | Loss: 0.381954
Epoch: 2 | Batch: 1600/40000 (4%) | Loss: 0.219849
Epoch: 2 | Batch: 1760/40000 (4%) | Loss: 0.192726
Epoch: 2 | Batch: 1920/40000 (5%) | Loss: 0.063844
Epoch: 2 | Batch: 2080/40000 (5%) | Loss: 0.402234
Epoch: 2 | Batch: 2240/40000 (6%) | Loss: 0.274522
Epoch: 2 | Batch: 2400/40000 (6%) | Loss: 0.382609
Epoch: 2 | Batch: 2560/40000 (6%) | Loss: 0.308066
Epoch: 2 | Batch: 2720/40000 (7%) | Loss: 0.249826
Epoch: 2 | Batch: 2880/40000 (7%) | Loss: 0.075259
Epoch: 2 | Batch: 3040/40000 (8%) | Loss: 0.250504
Epoch: 2 | Batch: 3200/40000 (8%) | Loss: 0.172292
Epoch: 2 | Batch: 3360/40000 (8%) | Loss: 0.159047
Epoch: 2 | Batch: 3520/40000 (9%) | Loss: 0.476455
Epoch: 2 | Batch: 3680/40000 (9%) | Loss: 0.277755
Epoch: 2 | Batch: 3840/40000 (10%) | Loss: 0.048509
Epoch: 2 | Batch: 4000/40000 (10%) | Loss: 0.211855
Epoch: 2 | Batch: 4160/40000 (10%) | Loss: 0.195357
Epoch: 2 | Batch: 4320/40000 (11%) | Loss: 0.282991
Epoch: 2 | Batch: 4480/40000 (11%) | Loss: 0.162400
Epoch: 2 | Batch: 4640/40000 (12%) | Loss: 0.656178
Epoch: 2 | Batch: 4800/40000 (12%) | Loss: 0.127307
Epoch: 2 | Batch: 4960/40000 (12%) | Loss: 0.244164
Epoch: 2 | Batch: 5120/40000 (13%) | Loss: 0.497209
Epoch: 2 | Batch: 5280/40000 (13%) | Loss: 0.200896
Epoch: 2 | Batch: 5440/40000 (14%) | Loss: 0.417773
Epoch: 2 | Batch: 5600/40000 (14%) | Loss: 0.332478
Epoch: 2 | Batch: 5760/40000 (14%) | Loss: 0.139673
Epoch: 2 | Batch: 5920/40000 (15%) | Loss: 0.119642
Epoch: 2 | Batch: 6080/40000 (15%) | Loss: 0.538881
Epoch: 2 | Batch: 6240/40000 (16%) | Loss: 0.201118
Epoch: 2 | Batch: 6400/40000 (16%) | Loss: 0.242621
Epoch: 2 | Batch: 6560/40000 (16%) | Loss: 0.398566
Epoch: 2 | Batch: 6720/40000 (17%) | Loss: 0.152883
Epoch: 2 | Batch: 6880/40000 (17%) | Loss: 0.394102
Epoch: 2 | Batch: 7040/40000 (18%) | Loss: 0.391988
Epoch: 2 | Batch: 7200/40000 (18%) | Loss: 0.326714
Epoch: 2 | Batch: 7360/40000 (18%) | Loss: 0.265821
Epoch: 2 | Batch: 7520/40000 (19%) | Loss: 0.309172
Epoch: 2 | Batch: 7680/40000 (19%) | Loss: 0.327890
Epoch: 2 | Batch: 7840/40000 (20%) | Loss: 0.114986
Epoch: 2 | Batch: 8000/40000 (20%) | Loss: 0.193553
Epoch: 2 | Batch: 8160/40000 (20%) | Loss: 0.309420
Epoch: 2 | Batch: 8320/40000 (21%) | Loss: 0.293719
Epoch: 2 | Batch: 8480/40000 (21%) | Loss: 0.237934
Epoch: 2 | Batch: 8640/40000 (22%) | Loss: 0.289029
Epoch: 2 | Batch: 8800/40000 (22%) | Loss: 0.508726
Epoch: 2 | Batch: 8960/40000 (22%) | Loss: 0.099588
Epoch: 2 | Batch: 9120/40000 (23%) | Loss: 0.167594
Epoch: 2 | Batch: 9280/40000 (23%) | Loss: 0.429170
Epoch: 2 | Batch: 9440/40000 (24%) | Loss: 0.238721
Epoch: 2 | Batch: 9600/40000 (24%) | Loss: 0.070085
Epoch: 2 | Batch: 9760/40000 (24%) | Loss: 0.325273
Epoch: 2 | Batch: 9920/40000 (25%) | Loss: 0.185450
Epoch: 2 | Batch: 10080/40000 (25%) | Loss: 0.233540
Epoch: 2 | Batch: 10240/40000 (26%) | Loss: 0.109126
Epoch: 2 | Batch: 10400/40000 (26%) | Loss: 0.582992
Epoch: 2 | Batch: 10560/40000 (26%) | Loss: 0.389799
Epoch: 2 | Batch: 10720/40000 (27%) | Loss: 0.403321
Epoch: 2 | Batch: 10880/40000 (27%) | Loss: 0.412540
Epoch: 2 | Batch: 11040/40000 (28%) | Loss: 0.249325
Epoch: 2 | Batch: 11200/40000 (28%) | Loss: 0.134123
Epoch: 2 | Batch: 11360/40000 (28%) | Loss: 0.337802
Epoch: 2 | Batch: 11520/40000 (29%) | Loss: 0.452141
Epoch: 2 | Batch: 11680/40000 (29%) | Loss: 0.545196
Epoch: 2 | Batch: 11840/40000 (30%) | Loss: 0.404395
Epoch: 2 | Batch: 12000/40000 (30%) | Loss: 0.280543
Epoch: 2 | Batch: 12160/40000 (30%) | Loss: 0.125077
Epoch: 2 | Batch: 12320/40000 (31%) | Loss: 0.219593
Epoch: 2 | Batch: 12480/40000 (31%) | Loss: 0.275223
Epoch: 2 | Batch: 12640/40000 (32%) | Loss: 0.405934
Epoch: 2 | Batch: 12800/40000 (32%) | Loss: 0.281698
Epoch: 2 | Batch: 12960/40000 (32%) | Loss: 0.151817
Epoch: 2 | Batch: 13120/40000 (33%) | Loss: 0.208288
Epoch: 2 | Batch: 13280/40000 (33%) | Loss: 0.179648
Epoch: 2 | Batch: 13440/40000 (34%) | Loss: 0.410117
Epoch: 2 | Batch: 13600/40000 (34%) | Loss: 0.312933
Epoch: 2 | Batch: 13760/40000 (34%) | Loss: 0.106878
Epoch: 2 | Batch: 13920/40000 (35%) | Loss: 0.260086
Epoch: 2 | Batch: 14080/40000 (35%) | Loss: 0.257937
Epoch: 2 | Batch: 14240/40000 (36%) | Loss: 0.475524
Epoch: 2 | Batch: 14400/40000 (36%) | Loss: 0.494769
Epoch: 2 | Batch: 14560/40000 (36%) | Loss: 0.078898
Epoch: 2 | Batch: 14720/40000 (37%) | Loss: 0.393763
Epoch: 2 | Batch: 14880/40000 (37%) | Loss: 0.228210
Epoch: 2 | Batch: 15040/40000 (38%) | Loss: 0.118394
Epoch: 2 | Batch: 15200/40000 (38%) | Loss: 0.203370
Epoch: 2 | Batch: 15360/40000 (38%) | Loss: 0.096581
Epoch: 2 | Batch: 15520/40000 (39%) | Loss: 0.573502
Epoch: 2 | Batch: 15680/40000 (39%) | Loss: 0.384361
Epoch: 2 | Batch: 15840/40000 (40%) | Loss: 0.201164
Epoch: 2 | Batch: 16000/40000 (40%) | Loss: 0.373522
Epoch: 2 | Batch: 16160/40000 (40%) | Loss: 0.391624
Epoch: 2 | Batch: 16320/40000 (41%) | Loss: 0.342831
Epoch: 2 | Batch: 16480/40000 (41%) | Loss: 0.215604
Epoch: 2 | Batch: 16640/40000 (42%) | Loss: 0.391782
Epoch: 2 | Batch: 16800/40000 (42%) | Loss: 0.465752
Epoch: 2 | Batch: 16960/40000 (42%) | Loss: 0.560098
Epoch: 2 | Batch: 17120/40000 (43%) | Loss: 0.148347
Epoch: 2 | Batch: 17280/40000 (43%) | Loss: 0.111349
Epoch: 2 | Batch: 17440/40000 (44%) | Loss: 0.181988
Epoch: 2 | Batch: 17600/40000 (44%) | Loss: 0.196275
Epoch: 2 | Batch: 17760/40000 (44%) | Loss: 0.315210
Epoch: 2 | Batch: 17920/40000 (45%) | Loss: 0.231219
Epoch: 2 | Batch: 18080/40000 (45%) | Loss: 0.090383
Epoch: 2 | Batch: 18240/40000 (46%) | Loss: 0.457640
Epoch: 2 | Batch: 18400/40000 (46%) | Loss: 0.061092
Epoch: 2 | Batch: 18560/40000 (46%) | Loss: 0.541884
Epoch: 2 | Batch: 18720/40000 (47%) | Loss: 0.474135
Epoch: 2 | Batch: 18880/40000 (47%) | Loss: 0.254092
Epoch: 2 | Batch: 19040/40000 (48%) | Loss: 0.555353
Epoch: 2 | Batch: 19200/40000 (48%) | Loss: 0.234632
Epoch: 2 | Batch: 19360/40000 (48%) | Loss: 0.216397
Epoch: 2 | Batch: 19520/40000 (49%) | Loss: 0.216119
Epoch: 2 | Batch: 19680/40000 (49%) | Loss: 0.124321
Epoch: 2 | Batch: 19840/40000 (50%) | Loss: 0.361293
Epoch: 2 | Batch: 20000/40000 (50%) | Loss: 0.057647
Epoch: 2 | Batch: 20160/40000 (50%) | Loss: 0.404445
Epoch: 2 | Batch: 20320/40000 (51%) | Loss: 0.179632
Epoch: 2 | Batch: 20480/40000 (51%) | Loss: 0.050556
Epoch: 2 | Batch: 20640/40000 (52%) | Loss: 0.118795
Epoch: 2 | Batch: 20800/40000 (52%) | Loss: 0.398123
Epoch: 2 | Batch: 20960/40000 (52%) | Loss: 0.138326
Epoch: 2 | Batch: 21120/40000 (53%) | Loss: 0.051523
Epoch: 2 | Batch: 21280/40000 (53%) | Loss: 0.351684
Epoch: 2 | Batch: 21440/40000 (54%) | Loss: 0.264246
Epoch: 2 | Batch: 21600/40000 (54%) | Loss: 0.044032
Epoch: 2 | Batch: 21760/40000 (54%) | Loss: 0.281633
Epoch: 2 | Batch: 21920/40000 (55%) | Loss: 0.297244
Epoch: 2 | Batch: 22080/40000 (55%) | Loss: 0.285963
Epoch: 2 | Batch: 22240/40000 (56%) | Loss: 0.193182
Epoch: 2 | Batch: 22400/40000 (56%) | Loss: 0.534441
Epoch: 2 | Batch: 22560/40000 (56%) | Loss: 0.142326
Epoch: 2 | Batch: 22720/40000 (57%) | Loss: 0.209267
Epoch: 2 | Batch: 22880/40000 (57%) | Loss: 0.214757
Epoch: 2 | Batch: 23040/40000 (58%) | Loss: 0.448397
Epoch: 2 | Batch: 23200/40000 (58%) | Loss: 0.208021
Epoch: 2 | Batch: 23360/40000 (58%) | Loss: 0.279114
Epoch: 2 | Batch: 23520/40000 (59%) | Loss: 0.132963
Epoch: 2 | Batch: 23680/40000 (59%) | Loss: 0.166303
Epoch: 2 | Batch: 23840/40000 (60%) | Loss: 0.461937
Epoch: 2 | Batch: 24000/40000 (60%) | Loss: 0.169977
Epoch: 2 | Batch: 24160/40000 (60%) | Loss: 0.150512
Epoch: 2 | Batch: 24320/40000 (61%) | Loss: 0.799249
Epoch: 2 | Batch: 24480/40000 (61%) | Loss: 0.074381
Epoch: 2 | Batch: 24640/40000 (62%) | Loss: 0.459302
Epoch: 2 | Batch: 24800/40000 (62%) | Loss: 0.807454
Epoch: 2 | Batch: 24960/40000 (62%) | Loss: 0.233074
Epoch: 2 | Batch: 25120/40000 (63%) | Loss: 0.312219
Epoch: 2 | Batch: 25280/40000 (63%) | Loss: 0.398451
Epoch: 2 | Batch: 25440/40000 (64%) | Loss: 0.195861
Epoch: 2 | Batch: 25600/40000 (64%) | Loss: 0.143954
Epoch: 2 | Batch: 25760/40000 (64%) | Loss: 0.344698
Epoch: 2 | Batch: 25920/40000 (65%) | Loss: 0.394661
Epoch: 2 | Batch: 26080/40000 (65%) | Loss: 0.226421
Epoch: 2 | Batch: 26240/40000 (66%) | Loss: 0.197148
Epoch: 2 | Batch: 26400/40000 (66%) | Loss: 0.173814
Epoch: 2 | Batch: 26560/40000 (66%) | Loss: 0.230210
Epoch: 2 | Batch: 26720/40000 (67%) | Loss: 0.209123
Epoch: 2 | Batch: 26880/40000 (67%) | Loss: 0.343629
Epoch: 2 | Batch: 27040/40000 (68%) | Loss: 0.404494
Epoch: 2 | Batch: 27200/40000 (68%) | Loss: 0.379534
Epoch: 2 | Batch: 27360/40000 (68%) | Loss: 0.118022
Epoch: 2 | Batch: 27520/40000 (69%) | Loss: 0.095432
Epoch: 2 | Batch: 27680/40000 (69%) | Loss: 0.372792
Epoch: 2 | Batch: 27840/40000 (70%) | Loss: 0.191153
Epoch: 2 | Batch: 28000/40000 (70%) | Loss: 0.335232
Epoch: 2 | Batch: 28160/40000 (70%) | Loss: 0.309727
Epoch: 2 | Batch: 28320/40000 (71%) | Loss: 0.302349
Epoch: 2 | Batch: 28480/40000 (71%) | Loss: 0.138899
Epoch: 2 | Batch: 28640/40000 (72%) | Loss: 0.190048
Epoch: 2 | Batch: 28800/40000 (72%) | Loss: 0.308278
Epoch: 2 | Batch: 28960/40000 (72%) | Loss: 0.138293
Epoch: 2 | Batch: 29120/40000 (73%) | Loss: 0.350738
Epoch: 2 | Batch: 29280/40000 (73%) | Loss: 0.573003
Epoch: 2 | Batch: 29440/40000 (74%) | Loss: 0.179819
Epoch: 2 | Batch: 29600/40000 (74%) | Loss: 0.301889
Epoch: 2 | Batch: 29760/40000 (74%) | Loss: 0.587494
Epoch: 2 | Batch: 29920/40000 (75%) | Loss: 0.075859
Epoch: 2 | Batch: 30080/40000 (75%) | Loss: 0.318252
Epoch: 2 | Batch: 30240/40000 (76%) | Loss: 0.382839
Epoch: 2 | Batch: 30400/40000 (76%) | Loss: 0.373083
Epoch: 2 | Batch: 30560/40000 (76%) | Loss: 0.364569
Epoch: 2 | Batch: 30720/40000 (77%) | Loss: 0.505289
Epoch: 2 | Batch: 30880/40000 (77%) | Loss: 0.253429
Epoch: 2 | Batch: 31040/40000 (78%) | Loss: 0.217985
Epoch: 2 | Batch: 31200/40000 (78%) | Loss: 0.268236
Epoch: 2 | Batch: 31360/40000 (78%) | Loss: 0.345453
Epoch: 2 | Batch: 31520/40000 (79%) | Loss: 0.141374
Epoch: 2 | Batch: 31680/40000 (79%) | Loss: 0.172289
Epoch: 2 | Batch: 31840/40000 (80%) | Loss: 0.146910
Epoch: 2 | Batch: 32000/40000 (80%) | Loss: 0.263045
Epoch: 2 | Batch: 32160/40000 (80%) | Loss: 0.273247
Epoch: 2 | Batch: 32320/40000 (81%) | Loss: 0.089805
Epoch: 2 | Batch: 32480/40000 (81%) | Loss: 0.062378
Epoch: 2 | Batch: 32640/40000 (82%) | Loss: 0.382532
Epoch: 2 | Batch: 32800/40000 (82%) | Loss: 0.428019
Epoch: 2 | Batch: 32960/40000 (82%) | Loss: 0.385975
Epoch: 2 | Batch: 33120/40000 (83%) | Loss: 0.298794
Epoch: 2 | Batch: 33280/40000 (83%) | Loss: 0.435711
Epoch: 2 | Batch: 33440/40000 (84%) | Loss: 0.220959
Epoch: 2 | Batch: 33600/40000 (84%) | Loss: 0.159147
Epoch: 2 | Batch: 33760/40000 (84%) | Loss: 0.112467
Epoch: 2 | Batch: 33920/40000 (85%) | Loss: 0.241121
Epoch: 2 | Batch: 34080/40000 (85%) | Loss: 0.473132
Epoch: 2 | Batch: 34240/40000 (86%) | Loss: 0.406748
Epoch: 2 | Batch: 34400/40000 (86%) | Loss: 0.482709
Epoch: 2 | Batch: 34560/40000 (86%) | Loss: 0.259571
Epoch: 2 | Batch: 34720/40000 (87%) | Loss: 0.278123
Epoch: 2 | Batch: 34880/40000 (87%) | Loss: 0.142854
Epoch: 2 | Batch: 35040/40000 (88%) | Loss: 0.107196
Epoch: 2 | Batch: 35200/40000 (88%) | Loss: 0.074313
Epoch: 2 | Batch: 35360/40000 (88%) | Loss: 0.199414
Epoch: 2 | Batch: 35520/40000 (89%) | Loss: 0.192507
Epoch: 2 | Batch: 35680/40000 (89%) | Loss: 0.394584
Epoch: 2 | Batch: 35840/40000 (90%) | Loss: 0.208814
Epoch: 2 | Batch: 36000/40000 (90%) | Loss: 0.311521
Epoch: 2 | Batch: 36160/40000 (90%) | Loss: 0.304101
Epoch: 2 | Batch: 36320/40000 (91%) | Loss: 0.269135
Epoch: 2 | Batch: 36480/40000 (91%) | Loss: 0.611150
Epoch: 2 | Batch: 36640/40000 (92%) | Loss: 0.289152
Epoch: 2 | Batch: 36800/40000 (92%) | Loss: 0.428842
Epoch: 2 | Batch: 36960/40000 (92%) | Loss: 0.573600
Epoch: 2 | Batch: 37120/40000 (93%) | Loss: 0.093756
Epoch: 2 | Batch: 37280/40000 (93%) | Loss: 0.285883
Epoch: 2 | Batch: 37440/40000 (94%) | Loss: 0.086370
Epoch: 2 | Batch: 37600/40000 (94%) | Loss: 0.274034
Epoch: 2 | Batch: 37760/40000 (94%) | Loss: 0.184359
Epoch: 2 | Batch: 37920/40000 (95%) | Loss: 0.145509
Epoch: 2 | Batch: 38080/40000 (95%) | Loss: 0.141722
Epoch: 2 | Batch: 38240/40000 (96%) | Loss: 0.400603
Epoch: 2 | Batch: 38400/40000 (96%) | Loss: 0.066964
Epoch: 2 | Batch: 38560/40000 (96%) | Loss: 0.265219
Epoch: 2 | Batch: 38720/40000 (97%) | Loss: 0.194145
Epoch: 2 | Batch: 38880/40000 (97%) | Loss: 0.238954
Epoch: 2 | Batch: 39040/40000 (98%) | Loss: 0.381731
Epoch: 2 | Batch: 39200/40000 (98%) | Loss: 0.528218
Epoch: 2 | Batch: 39360/40000 (98%) | Loss: 0.419611
Epoch: 2 | Batch: 39520/40000 (99%) | Loss: 0.463878
Epoch: 2 | Batch: 39680/40000 (99%) | Loss: 0.502986
Epoch: 2 | Batch: 39840/40000 (100%) | Loss: 0.611741
* (Train) Epoch: 2 | Loss: 0.2750
Epoch: 2 | Batch: 0/5000 (0%) | Loss: 0.298349
Epoch: 2 | Batch: 160/5000 (3%) | Loss: 0.261958
Epoch: 2 | Batch: 320/5000 (6%) | Loss: 0.453212
Epoch: 2 | Batch: 480/5000 (10%) | Loss: 0.333944
Epoch: 2 | Batch: 640/5000 (13%) | Loss: 0.680434
Epoch: 2 | Batch: 800/5000 (16%) | Loss: 0.194390
Epoch: 2 | Batch: 960/5000 (19%) | Loss: 0.213642
Epoch: 2 | Batch: 1120/5000 (22%) | Loss: 0.333543
Epoch: 2 | Batch: 1280/5000 (26%) | Loss: 0.504140
Epoch: 2 | Batch: 1440/5000 (29%) | Loss: 0.322496
Epoch: 2 | Batch: 1600/5000 (32%) | Loss: 0.138495
Epoch: 2 | Batch: 1760/5000 (35%) | Loss: 0.806541
Epoch: 2 | Batch: 1920/5000 (38%) | Loss: 0.104912
Epoch: 2 | Batch: 2080/5000 (42%) | Loss: 0.208108
Epoch: 2 | Batch: 2240/5000 (45%) | Loss: 0.296692
Epoch: 2 | Batch: 2400/5000 (48%) | Loss: 0.282848
Epoch: 2 | Batch: 2560/5000 (51%) | Loss: 0.401212
Epoch: 2 | Batch: 2720/5000 (54%) | Loss: 0.212650
Epoch: 2 | Batch: 2880/5000 (58%) | Loss: 0.170244
Epoch: 2 | Batch: 3040/5000 (61%) | Loss: 0.358986
Epoch: 2 | Batch: 3200/5000 (64%) | Loss: 0.375113
Epoch: 2 | Batch: 3360/5000 (67%) | Loss: 0.638566
Epoch: 2 | Batch: 3520/5000 (70%) | Loss: 0.521616
Epoch: 2 | Batch: 3680/5000 (74%) | Loss: 0.329137
Epoch: 2 | Batch: 3840/5000 (77%) | Loss: 0.292636
Epoch: 2 | Batch: 4000/5000 (80%) | Loss: 0.342282
Epoch: 2 | Batch: 4160/5000 (83%) | Loss: 0.549721
Epoch: 2 | Batch: 4320/5000 (86%) | Loss: 0.366982
Epoch: 2 | Batch: 4480/5000 (90%) | Loss: 0.307126
Epoch: 2 | Batch: 4640/5000 (93%) | Loss: 0.481264
Epoch: 2 | Batch: 4800/5000 (96%) | Loss: 0.467702
Epoch: 2 | Batch: 4960/5000 (99%) | Loss: 0.243973
* (Validation) Epoch: 2 | Loss: 0.3619
* Saved
Epoch: 3 | Batch: 0/40000 (0%) | Loss: 0.148002
Epoch: 3 | Batch: 160/40000 (0%) | Loss: 0.181456
Epoch: 3 | Batch: 320/40000 (1%) | Loss: 0.086407
Epoch: 3 | Batch: 480/40000 (1%) | Loss: 0.075811
Epoch: 3 | Batch: 640/40000 (2%) | Loss: 0.153257
Epoch: 3 | Batch: 800/40000 (2%) | Loss: 0.050008
Epoch: 3 | Batch: 960/40000 (2%) | Loss: 0.015072
Epoch: 3 | Batch: 1120/40000 (3%) | Loss: 0.023447
Epoch: 3 | Batch: 1280/40000 (3%) | Loss: 0.125142
Epoch: 3 | Batch: 1440/40000 (4%) | Loss: 0.209203
Epoch: 3 | Batch: 1600/40000 (4%) | Loss: 0.029537
Epoch: 3 | Batch: 1760/40000 (4%) | Loss: 0.139027
Epoch: 3 | Batch: 1920/40000 (5%) | Loss: 0.189015
Epoch: 3 | Batch: 2080/40000 (5%) | Loss: 0.034509
Epoch: 3 | Batch: 2240/40000 (6%) | Loss: 0.378226
Epoch: 3 | Batch: 2400/40000 (6%) | Loss: 0.320479
Epoch: 3 | Batch: 2560/40000 (6%) | Loss: 0.085323
Epoch: 3 | Batch: 2720/40000 (7%) | Loss: 0.017853
Epoch: 3 | Batch: 2880/40000 (7%) | Loss: 0.007691
Epoch: 3 | Batch: 3040/40000 (8%) | Loss: 0.040731
Epoch: 3 | Batch: 3200/40000 (8%) | Loss: 0.230996
Epoch: 3 | Batch: 3360/40000 (8%) | Loss: 0.034472
Epoch: 3 | Batch: 3520/40000 (9%) | Loss: 0.182199
Epoch: 3 | Batch: 3680/40000 (9%) | Loss: 0.268016
Epoch: 3 | Batch: 3840/40000 (10%) | Loss: 0.090692
Epoch: 3 | Batch: 4000/40000 (10%) | Loss: 0.153292
Epoch: 3 | Batch: 4160/40000 (10%) | Loss: 0.453095
Epoch: 3 | Batch: 4320/40000 (11%) | Loss: 0.080343
Epoch: 3 | Batch: 4480/40000 (11%) | Loss: 0.145323
Epoch: 3 | Batch: 4640/40000 (12%) | Loss: 0.045477
Epoch: 3 | Batch: 4800/40000 (12%) | Loss: 0.041642
Epoch: 3 | Batch: 4960/40000 (12%) | Loss: 0.317198
Epoch: 3 | Batch: 5120/40000 (13%) | Loss: 0.026749
Epoch: 3 | Batch: 5280/40000 (13%) | Loss: 0.073223
Epoch: 3 | Batch: 5440/40000 (14%) | Loss: 0.046512
Epoch: 3 | Batch: 5600/40000 (14%) | Loss: 0.037034
Epoch: 3 | Batch: 5760/40000 (14%) | Loss: 0.100103
Epoch: 3 | Batch: 5920/40000 (15%) | Loss: 0.065198
Epoch: 3 | Batch: 6080/40000 (15%) | Loss: 0.072941
Epoch: 3 | Batch: 6240/40000 (16%) | Loss: 0.115209
Epoch: 3 | Batch: 6400/40000 (16%) | Loss: 0.010235
Epoch: 3 | Batch: 6560/40000 (16%) | Loss: 0.082604
Epoch: 3 | Batch: 6720/40000 (17%) | Loss: 0.192951
Epoch: 3 | Batch: 6880/40000 (17%) | Loss: 0.125446
Epoch: 3 | Batch: 7040/40000 (18%) | Loss: 0.091622
Epoch: 3 | Batch: 7200/40000 (18%) | Loss: 0.048254
Epoch: 3 | Batch: 7360/40000 (18%) | Loss: 0.153670
Epoch: 3 | Batch: 7520/40000 (19%) | Loss: 0.157338
Epoch: 3 | Batch: 7680/40000 (19%) | Loss: 0.129119
Epoch: 3 | Batch: 7840/40000 (20%) | Loss: 0.107772
Epoch: 3 | Batch: 8000/40000 (20%) | Loss: 0.117099
Epoch: 3 | Batch: 8160/40000 (20%) | Loss: 0.057099
Epoch: 3 | Batch: 8320/40000 (21%) | Loss: 0.062219
Epoch: 3 | Batch: 8480/40000 (21%) | Loss: 0.031133
Epoch: 3 | Batch: 8640/40000 (22%) | Loss: 0.032015
Epoch: 3 | Batch: 8800/40000 (22%) | Loss: 0.027038
Epoch: 3 | Batch: 8960/40000 (22%) | Loss: 0.275302
Epoch: 3 | Batch: 9120/40000 (23%) | Loss: 0.315197
Epoch: 3 | Batch: 9280/40000 (23%) | Loss: 0.026000
Epoch: 3 | Batch: 9440/40000 (24%) | Loss: 0.090183
Epoch: 3 | Batch: 9600/40000 (24%) | Loss: 0.408675
Epoch: 3 | Batch: 9760/40000 (24%) | Loss: 0.055400
Epoch: 3 | Batch: 9920/40000 (25%) | Loss: 0.348533
Epoch: 3 | Batch: 10080/40000 (25%) | Loss: 0.173907
Epoch: 3 | Batch: 10240/40000 (26%) | Loss: 0.075116
Epoch: 3 | Batch: 10400/40000 (26%) | Loss: 0.046070
Epoch: 3 | Batch: 10560/40000 (26%) | Loss: 0.295656
Epoch: 3 | Batch: 10720/40000 (27%) | Loss: 0.112874
Epoch: 3 | Batch: 10880/40000 (27%) | Loss: 0.089301
Epoch: 3 | Batch: 11040/40000 (28%) | Loss: 0.094627
Epoch: 3 | Batch: 11200/40000 (28%) | Loss: 0.242274
Epoch: 3 | Batch: 11360/40000 (28%) | Loss: 0.098361
Epoch: 3 | Batch: 11520/40000 (29%) | Loss: 0.163675
Epoch: 3 | Batch: 11680/40000 (29%) | Loss: 0.125724
Epoch: 3 | Batch: 11840/40000 (30%) | Loss: 0.166268
Epoch: 3 | Batch: 12000/40000 (30%) | Loss: 0.053411
Epoch: 3 | Batch: 12160/40000 (30%) | Loss: 0.054782
Epoch: 3 | Batch: 12320/40000 (31%) | Loss: 0.030863
Epoch: 3 | Batch: 12480/40000 (31%) | Loss: 0.195467
Epoch: 3 | Batch: 12640/40000 (32%) | Loss: 0.070927
Epoch: 3 | Batch: 12800/40000 (32%) | Loss: 0.179042
Epoch: 3 | Batch: 12960/40000 (32%) | Loss: 0.107744
Epoch: 3 | Batch: 13120/40000 (33%) | Loss: 0.040243
Epoch: 3 | Batch: 13280/40000 (33%) | Loss: 0.212337
Epoch: 3 | Batch: 13440/40000 (34%) | Loss: 0.011233
Epoch: 3 | Batch: 13600/40000 (34%) | Loss: 0.163442
Epoch: 3 | Batch: 13760/40000 (34%) | Loss: 0.027350
Epoch: 3 | Batch: 13920/40000 (35%) | Loss: 0.024971
Epoch: 3 | Batch: 14080/40000 (35%) | Loss: 0.240621
Epoch: 3 | Batch: 14240/40000 (36%) | Loss: 0.095427
Epoch: 3 | Batch: 14400/40000 (36%) | Loss: 0.325916
Epoch: 3 | Batch: 14560/40000 (36%) | Loss: 0.050080
Epoch: 3 | Batch: 14720/40000 (37%) | Loss: 0.213254
Epoch: 3 | Batch: 14880/40000 (37%) | Loss: 0.098080
Epoch: 3 | Batch: 15040/40000 (38%) | Loss: 0.086682
Epoch: 3 | Batch: 15200/40000 (38%) | Loss: 0.057504
Epoch: 3 | Batch: 15360/40000 (38%) | Loss: 0.053043
Epoch: 3 | Batch: 15520/40000 (39%) | Loss: 0.032867
Epoch: 3 | Batch: 15680/40000 (39%) | Loss: 0.577980
Epoch: 3 | Batch: 15840/40000 (40%) | Loss: 0.278173
Epoch: 3 | Batch: 16000/40000 (40%) | Loss: 0.104103
Epoch: 3 | Batch: 16160/40000 (40%) | Loss: 0.096129
Epoch: 3 | Batch: 16320/40000 (41%) | Loss: 0.080438
Epoch: 3 | Batch: 16480/40000 (41%) | Loss: 0.080446
Epoch: 3 | Batch: 16640/40000 (42%) | Loss: 0.130302
Epoch: 3 | Batch: 16800/40000 (42%) | Loss: 0.183312
Epoch: 3 | Batch: 16960/40000 (42%) | Loss: 0.063833
Epoch: 3 | Batch: 17120/40000 (43%) | Loss: 0.011606
Epoch: 3 | Batch: 17280/40000 (43%) | Loss: 0.167849
Epoch: 3 | Batch: 17440/40000 (44%) | Loss: 0.214546
Epoch: 3 | Batch: 17600/40000 (44%) | Loss: 0.018686
Epoch: 3 | Batch: 17760/40000 (44%) | Loss: 0.136446
Epoch: 3 | Batch: 17920/40000 (45%) | Loss: 0.022599
Epoch: 3 | Batch: 18080/40000 (45%) | Loss: 0.099779
Epoch: 3 | Batch: 18240/40000 (46%) | Loss: 0.082321
Epoch: 3 | Batch: 18400/40000 (46%) | Loss: 0.081055
Epoch: 3 | Batch: 18560/40000 (46%) | Loss: 0.092565
Epoch: 3 | Batch: 18720/40000 (47%) | Loss: 0.305955
Epoch: 3 | Batch: 18880/40000 (47%) | Loss: 0.196182
Epoch: 3 | Batch: 19040/40000 (48%) | Loss: 0.230474
Epoch: 3 | Batch: 19200/40000 (48%) | Loss: 0.661990
Epoch: 3 | Batch: 19360/40000 (48%) | Loss: 0.180309
Epoch: 3 | Batch: 19520/40000 (49%) | Loss: 0.185146
Epoch: 3 | Batch: 19680/40000 (49%) | Loss: 0.126869
Epoch: 3 | Batch: 19840/40000 (50%) | Loss: 0.031809
Epoch: 3 | Batch: 20000/40000 (50%) | Loss: 0.147256
Epoch: 3 | Batch: 20160/40000 (50%) | Loss: 0.086378
Epoch: 3 | Batch: 20320/40000 (51%) | Loss: 0.248778
Epoch: 3 | Batch: 20480/40000 (51%) | Loss: 0.103227
Epoch: 3 | Batch: 20640/40000 (52%) | Loss: 0.026198
Epoch: 3 | Batch: 20800/40000 (52%) | Loss: 0.375503
Epoch: 3 | Batch: 20960/40000 (52%) | Loss: 0.018052
Epoch: 3 | Batch: 21120/40000 (53%) | Loss: 0.230624
Epoch: 3 | Batch: 21280/40000 (53%) | Loss: 0.293447
Epoch: 3 | Batch: 21440/40000 (54%) | Loss: 0.187358
Epoch: 3 | Batch: 21600/40000 (54%) | Loss: 0.035730
Epoch: 3 | Batch: 21760/40000 (54%) | Loss: 0.095685
Epoch: 3 | Batch: 21920/40000 (55%) | Loss: 0.314768
Epoch: 3 | Batch: 22080/40000 (55%) | Loss: 0.055786
Epoch: 3 | Batch: 22240/40000 (56%) | Loss: 0.484950
Epoch: 3 | Batch: 22400/40000 (56%) | Loss: 0.089837
Epoch: 3 | Batch: 22560/40000 (56%) | Loss: 0.103872
Epoch: 3 | Batch: 22720/40000 (57%) | Loss: 0.146013
Epoch: 3 | Batch: 22880/40000 (57%) | Loss: 0.216838
Epoch: 3 | Batch: 23040/40000 (58%) | Loss: 0.343330
Epoch: 3 | Batch: 23200/40000 (58%) | Loss: 0.251350
Epoch: 3 | Batch: 23360/40000 (58%) | Loss: 0.217100
Epoch: 3 | Batch: 23520/40000 (59%) | Loss: 0.194590
Epoch: 3 | Batch: 23680/40000 (59%) | Loss: 0.128580
Epoch: 3 | Batch: 23840/40000 (60%) | Loss: 0.243137
Epoch: 3 | Batch: 24000/40000 (60%) | Loss: 0.018404
Epoch: 3 | Batch: 24160/40000 (60%) | Loss: 0.226341
Epoch: 3 | Batch: 24320/40000 (61%) | Loss: 0.141362
Epoch: 3 | Batch: 24480/40000 (61%) | Loss: 0.043194
Epoch: 3 | Batch: 24640/40000 (62%) | Loss: 0.236217
Epoch: 3 | Batch: 24800/40000 (62%) | Loss: 0.071890
Epoch: 3 | Batch: 24960/40000 (62%) | Loss: 0.036784
Epoch: 3 | Batch: 25120/40000 (63%) | Loss: 0.029044
Epoch: 3 | Batch: 25280/40000 (63%) | Loss: 0.087609
Epoch: 3 | Batch: 25440/40000 (64%) | Loss: 0.329634
Epoch: 3 | Batch: 25600/40000 (64%) | Loss: 0.114486
Epoch: 3 | Batch: 25760/40000 (64%) | Loss: 0.463019
Epoch: 3 | Batch: 25920/40000 (65%) | Loss: 0.675978
Epoch: 3 | Batch: 26080/40000 (65%) | Loss: 0.255373
Epoch: 3 | Batch: 26240/40000 (66%) | Loss: 0.108128
Epoch: 3 | Batch: 26400/40000 (66%) | Loss: 0.167617
Epoch: 3 | Batch: 26560/40000 (66%) | Loss: 0.178324
Epoch: 3 | Batch: 26720/40000 (67%) | Loss: 0.018585
Epoch: 3 | Batch: 26880/40000 (67%) | Loss: 0.039676
Epoch: 3 | Batch: 27040/40000 (68%) | Loss: 0.203847
Epoch: 3 | Batch: 27200/40000 (68%) | Loss: 0.063610
Epoch: 3 | Batch: 27360/40000 (68%) | Loss: 0.079808
Epoch: 3 | Batch: 27520/40000 (69%) | Loss: 0.251396
Epoch: 3 | Batch: 27680/40000 (69%) | Loss: 0.009275
Epoch: 3 | Batch: 27840/40000 (70%) | Loss: 0.068197
Epoch: 3 | Batch: 28000/40000 (70%) | Loss: 0.220170
Epoch: 3 | Batch: 28160/40000 (70%) | Loss: 0.142571
Epoch: 3 | Batch: 28320/40000 (71%) | Loss: 0.221784
Epoch: 3 | Batch: 28480/40000 (71%) | Loss: 0.191182
Epoch: 3 | Batch: 28640/40000 (72%) | Loss: 0.023923
Epoch: 3 | Batch: 28800/40000 (72%) | Loss: 0.151171
Epoch: 3 | Batch: 28960/40000 (72%) | Loss: 0.036201
Epoch: 3 | Batch: 29120/40000 (73%) | Loss: 0.195330
Epoch: 3 | Batch: 29280/40000 (73%) | Loss: 0.156677
Epoch: 3 | Batch: 29440/40000 (74%) | Loss: 0.214801
Epoch: 3 | Batch: 29600/40000 (74%) | Loss: 0.041754
Epoch: 3 | Batch: 29760/40000 (74%) | Loss: 0.113783
Epoch: 3 | Batch: 29920/40000 (75%) | Loss: 0.309489
Epoch: 3 | Batch: 30080/40000 (75%) | Loss: 0.092965
Epoch: 3 | Batch: 30240/40000 (76%) | Loss: 0.051287
Epoch: 3 | Batch: 30400/40000 (76%) | Loss: 0.012787
Epoch: 3 | Batch: 30560/40000 (76%) | Loss: 0.010813
Epoch: 3 | Batch: 30720/40000 (77%) | Loss: 0.033411
Epoch: 3 | Batch: 30880/40000 (77%) | Loss: 0.070452
Epoch: 3 | Batch: 31040/40000 (78%) | Loss: 0.229039
Epoch: 3 | Batch: 31200/40000 (78%) | Loss: 0.131261
Epoch: 3 | Batch: 31360/40000 (78%) | Loss: 0.170237
Epoch: 3 | Batch: 31520/40000 (79%) | Loss: 0.043976
Epoch: 3 | Batch: 31680/40000 (79%) | Loss: 0.027598
Epoch: 3 | Batch: 31840/40000 (80%) | Loss: 0.133711
Epoch: 3 | Batch: 32000/40000 (80%) | Loss: 0.065563
Epoch: 3 | Batch: 32160/40000 (80%) | Loss: 0.054936
Epoch: 3 | Batch: 32320/40000 (81%) | Loss: 0.150706
Epoch: 3 | Batch: 32480/40000 (81%) | Loss: 0.072275
Epoch: 3 | Batch: 32640/40000 (82%) | Loss: 0.092004
Epoch: 3 | Batch: 32800/40000 (82%) | Loss: 0.182371
Epoch: 3 | Batch: 32960/40000 (82%) | Loss: 0.043916
Epoch: 3 | Batch: 33120/40000 (83%) | Loss: 0.051940
Epoch: 3 | Batch: 33280/40000 (83%) | Loss: 0.067462
Epoch: 3 | Batch: 33440/40000 (84%) | Loss: 0.281875
Epoch: 3 | Batch: 33600/40000 (84%) | Loss: 0.106667
Epoch: 3 | Batch: 33760/40000 (84%) | Loss: 0.217853
Epoch: 3 | Batch: 33920/40000 (85%) | Loss: 0.030481
Epoch: 3 | Batch: 34080/40000 (85%) | Loss: 0.055012
Epoch: 3 | Batch: 34240/40000 (86%) | Loss: 0.150358
Epoch: 3 | Batch: 34400/40000 (86%) | Loss: 0.044497
Epoch: 3 | Batch: 34560/40000 (86%) | Loss: 0.311939
Epoch: 3 | Batch: 34720/40000 (87%) | Loss: 0.097984
Epoch: 3 | Batch: 34880/40000 (87%) | Loss: 0.174313
Epoch: 3 | Batch: 35040/40000 (88%) | Loss: 0.111126
Epoch: 3 | Batch: 35200/40000 (88%) | Loss: 0.500431
Epoch: 3 | Batch: 35360/40000 (88%) | Loss: 0.105548
Epoch: 3 | Batch: 35520/40000 (89%) | Loss: 0.080805
Epoch: 3 | Batch: 35680/40000 (89%) | Loss: 0.220544
Epoch: 3 | Batch: 35840/40000 (90%) | Loss: 0.029022
Epoch: 3 | Batch: 36000/40000 (90%) | Loss: 0.069702
Epoch: 3 | Batch: 36160/40000 (90%) | Loss: 0.288839
Epoch: 3 | Batch: 36320/40000 (91%) | Loss: 0.464805
Epoch: 3 | Batch: 36480/40000 (91%) | Loss: 0.227438
Epoch: 3 | Batch: 36640/40000 (92%) | Loss: 0.157346
Epoch: 3 | Batch: 36800/40000 (92%) | Loss: 0.466872
Epoch: 3 | Batch: 36960/40000 (92%) | Loss: 0.169813
Epoch: 3 | Batch: 37120/40000 (93%) | Loss: 0.157347
Epoch: 3 | Batch: 37280/40000 (93%) | Loss: 0.047295
Epoch: 3 | Batch: 37440/40000 (94%) | Loss: 0.155160
Epoch: 3 | Batch: 37600/40000 (94%) | Loss: 0.164045
Epoch: 3 | Batch: 37760/40000 (94%) | Loss: 0.321981
Epoch: 3 | Batch: 37920/40000 (95%) | Loss: 0.086759
Epoch: 3 | Batch: 38080/40000 (95%) | Loss: 0.117725
Epoch: 3 | Batch: 38240/40000 (96%) | Loss: 0.330314
Epoch: 3 | Batch: 38400/40000 (96%) | Loss: 0.100933
Epoch: 3 | Batch: 38560/40000 (96%) | Loss: 0.282429
Epoch: 3 | Batch: 38720/40000 (97%) | Loss: 0.115320
Epoch: 3 | Batch: 38880/40000 (97%) | Loss: 0.043496
Epoch: 3 | Batch: 39040/40000 (98%) | Loss: 0.036573
Epoch: 3 | Batch: 39200/40000 (98%) | Loss: 0.164098
Epoch: 3 | Batch: 39360/40000 (98%) | Loss: 0.541483
Epoch: 3 | Batch: 39520/40000 (99%) | Loss: 0.318693
Epoch: 3 | Batch: 39680/40000 (99%) | Loss: 0.405821
Epoch: 3 | Batch: 39840/40000 (100%) | Loss: 0.108944
* (Train) Epoch: 3 | Loss: 0.1464
Epoch: 3 | Batch: 0/5000 (0%) | Loss: 0.612731
Epoch: 3 | Batch: 160/5000 (3%) | Loss: 0.087100
Epoch: 3 | Batch: 320/5000 (6%) | Loss: 0.511998
Epoch: 3 | Batch: 480/5000 (10%) | Loss: 0.882700
Epoch: 3 | Batch: 640/5000 (13%) | Loss: 0.334716
Epoch: 3 | Batch: 800/5000 (16%) | Loss: 0.481282
Epoch: 3 | Batch: 960/5000 (19%) | Loss: 0.403481
Epoch: 3 | Batch: 1120/5000 (22%) | Loss: 0.650995
Epoch: 3 | Batch: 1280/5000 (26%) | Loss: 0.399481
Epoch: 3 | Batch: 1440/5000 (29%) | Loss: 0.042386
Epoch: 3 | Batch: 1600/5000 (32%) | Loss: 0.374108
Epoch: 3 | Batch: 1760/5000 (35%) | Loss: 0.198322
Epoch: 3 | Batch: 1920/5000 (38%) | Loss: 0.507315
Epoch: 3 | Batch: 2080/5000 (42%) | Loss: 0.627012
Epoch: 3 | Batch: 2240/5000 (45%) | Loss: 0.264753
Epoch: 3 | Batch: 2400/5000 (48%) | Loss: 0.588390
Epoch: 3 | Batch: 2560/5000 (51%) | Loss: 0.914739
Epoch: 3 | Batch: 2720/5000 (54%) | Loss: 0.716290
Epoch: 3 | Batch: 2880/5000 (58%) | Loss: 0.339135
Epoch: 3 | Batch: 3040/5000 (61%) | Loss: 0.181293
Epoch: 3 | Batch: 3200/5000 (64%) | Loss: 0.568758
Epoch: 3 | Batch: 3360/5000 (67%) | Loss: 0.271986
Epoch: 3 | Batch: 3520/5000 (70%) | Loss: 0.114311
Epoch: 3 | Batch: 3680/5000 (74%) | Loss: 0.244904
Epoch: 3 | Batch: 3840/5000 (77%) | Loss: 0.138108
Epoch: 3 | Batch: 4000/5000 (80%) | Loss: 0.786977
Epoch: 3 | Batch: 4160/5000 (83%) | Loss: 0.118398
Epoch: 3 | Batch: 4320/5000 (86%) | Loss: 0.550867
Epoch: 3 | Batch: 4480/5000 (90%) | Loss: 0.258980
Epoch: 3 | Batch: 4640/5000 (93%) | Loss: 0.442666
Epoch: 3 | Batch: 4800/5000 (96%) | Loss: 0.498377
Epoch: 3 | Batch: 4960/5000 (99%) | Loss: 0.745083
* (Validation) Epoch: 3 | Loss: 0.4461
Traceback (most recent call last):
  File "code/train.py", line 146, in <module>
    accuracy, f1 = test_model(device)
  File "code/train.py", line 67, in test_model
    mdl.load_state_dict(check)
  File "/home1/06919/rvnair/research/text-classification/venv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 839, in load_state_dict
    self.__class__.__name__, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for BertMLP:
	Missing key(s) in state_dict: "bert.embeddings.word_embeddings.weight", "bert.embeddings.position_embeddings.weight", "bert.embeddings.token_type_embeddings.weight", "bert.embeddings.LayerNorm.weight", "bert.embeddings.LayerNorm.bias", "bert.encoder.layer.0.attention.self.query.weight", "bert.encoder.layer.0.attention.self.query.bias", "bert.encoder.layer.0.attention.self.key.weight", "bert.encoder.layer.0.attention.self.key.bias", "bert.encoder.layer.0.attention.self.value.weight", "bert.encoder.layer.0.attention.self.value.bias", "bert.encoder.layer.0.attention.output.dense.weight", "bert.encoder.layer.0.attention.output.dense.bias", "bert.encoder.layer.0.attention.output.LayerNorm.weight", "bert.encoder.layer.0.attention.output.LayerNorm.bias", "bert.encoder.layer.0.intermediate.dense.weight", "bert.encoder.layer.0.intermediate.dense.bias", "bert.encoder.layer.0.output.dense.weight", "bert.encoder.layer.0.output.dense.bias", "bert.encoder.layer.0.output.LayerNorm.weight", "bert.encoder.layer.0.output.LayerNorm.bias", "bert.encoder.layer.1.attention.self.query.weight", "bert.encoder.layer.1.attention.self.query.bias", "bert.encoder.layer.1.attention.self.key.weight", "bert.encoder.layer.1.attention.self.key.bias", "bert.encoder.layer.1.attention.self.value.weight", "bert.encoder.layer.1.attention.self.value.bias", "bert.encoder.layer.1.attention.output.dense.weight", "bert.encoder.layer.1.attention.output.dense.bias", "bert.encoder.layer.1.attention.output.LayerNorm.weight", "bert.encoder.layer.1.attention.output.LayerNorm.bias", "bert.encoder.layer.1.intermediate.dense.weight", "bert.encoder.layer.1.intermediate.dense.bias", "bert.encoder.layer.1.output.dense.weight", "bert.encoder.layer.1.output.dense.bias", "bert.encoder.layer.1.output.LayerNorm.weight", "bert.encoder.layer.1.output.LayerNorm.bias", "bert.encoder.layer.2.attention.self.query.weight", "bert.encoder.layer.2.attention.self.query.bias", "bert.encoder.layer.2.attention.self.key.weight", "bert.encoder.layer.2.attention.self.key.bias", "bert.encoder.layer.2.attention.self.value.weight", "bert.encoder.layer.2.attention.self.value.bias", "bert.encoder.layer.2.attention.output.dense.weight", "bert.encoder.layer.2.attention.output.dense.bias", "bert.encoder.layer.2.attention.output.LayerNorm.weight", "bert.encoder.layer.2.attention.output.LayerNorm.bias", "bert.encoder.layer.2.intermediate.dense.weight", "bert.encoder.layer.2.intermediate.dense.bias", "bert.encoder.layer.2.output.dense.weight", "bert.encoder.layer.2.output.dense.bias", "bert.encoder.layer.2.output.LayerNorm.weight", "bert.encoder.layer.2.output.LayerNorm.bias", "bert.encoder.layer.3.attention.self.query.weight", "bert.encoder.layer.3.attention.self.query.bias", "bert.encoder.layer.3.attention.self.key.weight", "bert.encoder.layer.3.attention.self.key.bias", "bert.encoder.layer.3.attention.self.value.weight", "bert.encoder.layer.3.attention.self.value.bias", "bert.encoder.layer.3.attention.output.dense.weight", "bert.encoder.layer.3.attention.output.dense.bias", "bert.encoder.layer.3.attention.output.LayerNorm.weight", "bert.encoder.layer.3.attention.output.LayerNorm.bias", "bert.encoder.layer.3.intermediate.dense.weight", "bert.encoder.layer.3.intermediate.dense.bias", "bert.encoder.layer.3.output.dense.weight", "bert.encoder.layer.3.output.dense.bias", "bert.encoder.layer.3.output.LayerNorm.weight", "bert.encoder.layer.3.output.LayerNorm.bias", "bert.encoder.layer.4.attention.self.query.weight", "bert.encoder.layer.4.attention.self.query.bias", "bert.encoder.layer.4.attention.self.key.weight", "bert.encoder.layer.4.attention.self.key.bias", "bert.encoder.layer.4.attention.self.value.weight", "bert.encoder.layer.4.attention.self.value.bias", "bert.encoder.layer.4.attention.output.dense.weight", "bert.encoder.layer.4.attention.output.dense.bias", "bert.encoder.layer.4.attention.output.LayerNorm.weight", "bert.encoder.layer.4.attention.output.LayerNorm.bias", "bert.encoder.layer.4.intermediate.dense.weight", "bert.encoder.layer.4.intermediate.dense.bias", "bert.encoder.layer.4.output.dense.weight", "bert.encoder.layer.4.output.dense.bias", "bert.encoder.layer.4.output.LayerNorm.weight", "bert.encoder.layer.4.output.LayerNorm.bias", "bert.encoder.layer.5.attention.self.query.weight", "bert.encoder.layer.5.attention.self.query.bias", "bert.encoder.layer.5.attention.self.key.weight", "bert.encoder.layer.5.attention.self.key.bias", "bert.encoder.layer.5.attention.self.value.weight", "bert.encoder.layer.5.attention.self.value.bias", "bert.encoder.layer.5.attention.output.dense.weight", "bert.encoder.layer.5.attention.output.dense.bias", "bert.encoder.layer.5.attention.output.LayerNorm.weight", "bert.encoder.layer.5.attention.output.LayerNorm.bias", "bert.encoder.layer.5.intermediate.dense.weight", "bert.encoder.layer.5.intermediate.dense.bias", "bert.encoder.layer.5.output.dense.weight", "bert.encoder.layer.5.output.dense.bias", "bert.encoder.layer.5.output.LayerNorm.weight", "bert.encoder.layer.5.output.LayerNorm.bias", "bert.encoder.layer.6.attention.self.query.weight", "bert.encoder.layer.6.attention.self.query.bias", "bert.encoder.layer.6.attention.self.key.weight", "bert.encoder.layer.6.attention.self.key.bias", "bert.encoder.layer.6.attention.self.value.weight", "bert.encoder.layer.6.attention.self.value.bias", "bert.encoder.layer.6.attention.output.dense.weight", "bert.encoder.layer.6.attention.output.dense.bias", "bert.encoder.layer.6.attention.output.LayerNorm.weight", "bert.encoder.layer.6.attention.output.LayerNorm.bias", "bert.encoder.layer.6.intermediate.dense.weight", "bert.encoder.layer.6.intermediate.dense.bias", "bert.encoder.layer.6.output.dense.weight", "bert.encoder.layer.6.output.dense.bias", "bert.encoder.layer.6.output.LayerNorm.weight", "bert.encoder.layer.6.output.LayerNorm.bias", "bert.encoder.layer.7.attention.self.query.weight", "bert.encoder.layer.7.attention.self.query.bias", "bert.encoder.layer.7.attention.self.key.weight", "bert.encoder.layer.7.attention.self.key.bias", "bert.encoder.layer.7.attention.self.value.weight", "bert.encoder.layer.7.attention.self.value.bias", "bert.encoder.layer.7.attention.output.dense.weight", "bert.encoder.layer.7.attention.output.dense.bias", "bert.encoder.layer.7.attention.output.LayerNorm.weight", "bert.encoder.layer.7.attention.output.LayerNorm.bias", "bert.encoder.layer.7.intermediate.dense.weight", "bert.encoder.layer.7.intermediate.dense.bias", "bert.encoder.layer.7.output.dense.weight", "bert.encoder.layer.7.output.dense.bias", "bert.encoder.layer.7.output.LayerNorm.weight", "bert.encoder.layer.7.output.LayerNorm.bias", "bert.encoder.layer.8.attention.self.query.weight", "bert.encoder.layer.8.attention.self.query.bias", "bert.encoder.layer.8.attention.self.key.weight", "bert.encoder.layer.8.attention.self.key.bias", "bert.encoder.layer.8.attention.self.value.weight", "bert.encoder.layer.8.attention.self.value.bias", "bert.encoder.layer.8.attention.output.dense.weight", "bert.encoder.layer.8.attention.output.dense.bias", "bert.encoder.layer.8.attention.output.LayerNorm.weight", "bert.encoder.layer.8.attention.output.LayerNorm.bias", "bert.encoder.layer.8.intermediate.dense.weight", "bert.encoder.layer.8.intermediate.dense.bias", "bert.encoder.layer.8.output.dense.weight", "bert.encoder.layer.8.output.dense.bias", "bert.encoder.layer.8.output.LayerNorm.weight", "bert.encoder.layer.8.output.LayerNorm.bias", "bert.encoder.layer.9.attention.self.query.weight", "bert.encoder.layer.9.attention.self.query.bias", "bert.encoder.layer.9.attention.self.key.weight", "bert.encoder.layer.9.attention.self.key.bias", "bert.encoder.layer.9.attention.self.value.weight", "bert.encoder.layer.9.attention.self.value.bias", "bert.encoder.layer.9.attention.output.dense.weight", "bert.encoder.layer.9.attention.output.dense.bias", "bert.encoder.layer.9.attention.output.LayerNorm.weight", "bert.encoder.layer.9.attention.output.LayerNorm.bias", "bert.encoder.layer.9.intermediate.dense.weight", "bert.encoder.layer.9.intermediate.dense.bias", "bert.encoder.layer.9.output.dense.weight", "bert.encoder.layer.9.output.dense.bias", "bert.encoder.layer.9.output.LayerNorm.weight", "bert.encoder.layer.9.output.LayerNorm.bias", "bert.encoder.layer.10.attention.self.query.weight", "bert.encoder.layer.10.attention.self.query.bias", "bert.encoder.layer.10.attention.self.key.weight", "bert.encoder.layer.10.attention.self.key.bias", "bert.encoder.layer.10.attention.self.value.weight", "bert.encoder.layer.10.attention.self.value.bias", "bert.encoder.layer.10.attention.output.dense.weight", "bert.encoder.layer.10.attention.output.dense.bias", "bert.encoder.layer.10.attention.output.LayerNorm.weight", "bert.encoder.layer.10.attention.output.LayerNorm.bias", "bert.encoder.layer.10.intermediate.dense.weight", "bert.encoder.layer.10.intermediate.dense.bias", "bert.encoder.layer.10.output.dense.weight", "bert.encoder.layer.10.output.dense.bias", "bert.encoder.layer.10.output.LayerNorm.weight", "bert.encoder.layer.10.output.LayerNorm.bias", "bert.encoder.layer.11.attention.self.query.weight", "bert.encoder.layer.11.attention.self.query.bias", "bert.encoder.layer.11.attention.self.key.weight", "bert.encoder.layer.11.attention.self.key.bias", "bert.encoder.layer.11.attention.self.value.weight", "bert.encoder.layer.11.attention.self.value.bias", "bert.encoder.layer.11.attention.output.dense.weight", "bert.encoder.layer.11.attention.output.dense.bias", "bert.encoder.layer.11.attention.output.LayerNorm.weight", "bert.encoder.layer.11.attention.output.LayerNorm.bias", "bert.encoder.layer.11.intermediate.dense.weight", "bert.encoder.layer.11.intermediate.dense.bias", "bert.encoder.layer.11.output.dense.weight", "bert.encoder.layer.11.output.dense.bias", "bert.encoder.layer.11.output.LayerNorm.weight", "bert.encoder.layer.11.output.LayerNorm.bias", "bert.pooler.dense.weight", "bert.pooler.dense.bias". 
	Unexpected key(s) in state_dict: "conv_0.weight", "conv_0.bias", "conv_1.weight", "conv_1.bias", "conv_2.weight", "conv_2.bias", "embeddings.weight". 
	size mismatch for fc.weight: copying a param with shape torch.Size([2, 300]) from checkpoint, the shape in current model is torch.Size([2, 768]).
using bert tokens
using bert tokens
using bert tokens
Epoch: 1 | Batch: 0/40000 (0%) | Loss: 0.727397
Epoch: 1 | Batch: 160/40000 (0%) | Loss: 0.696657
Epoch: 1 | Batch: 320/40000 (1%) | Loss: 0.608368
Epoch: 1 | Batch: 480/40000 (1%) | Loss: 0.608334
Epoch: 1 | Batch: 640/40000 (2%) | Loss: 0.561832
Epoch: 1 | Batch: 800/40000 (2%) | Loss: 0.504524
Epoch: 1 | Batch: 960/40000 (2%) | Loss: 0.467346
Epoch: 1 | Batch: 1120/40000 (3%) | Loss: 0.388233
Epoch: 1 | Batch: 1280/40000 (3%) | Loss: 0.487217
Epoch: 1 | Batch: 1440/40000 (4%) | Loss: 0.455317
Epoch: 1 | Batch: 1600/40000 (4%) | Loss: 0.438200
Epoch: 1 | Batch: 1760/40000 (4%) | Loss: 0.507727
Epoch: 1 | Batch: 1920/40000 (5%) | Loss: 0.525091
Epoch: 1 | Batch: 2080/40000 (5%) | Loss: 0.380939
Epoch: 1 | Batch: 2240/40000 (6%) | Loss: 0.554650
Epoch: 1 | Batch: 2400/40000 (6%) | Loss: 0.599463
Epoch: 1 | Batch: 2560/40000 (6%) | Loss: 0.619046
Epoch: 1 | Batch: 2720/40000 (7%) | Loss: 0.369774
Epoch: 1 | Batch: 2880/40000 (7%) | Loss: 0.667606
Epoch: 1 | Batch: 3040/40000 (8%) | Loss: 0.576849
Epoch: 1 | Batch: 3200/40000 (8%) | Loss: 0.536523
Epoch: 1 | Batch: 3360/40000 (8%) | Loss: 0.579103
Epoch: 1 | Batch: 3520/40000 (9%) | Loss: 0.713551
Epoch: 1 | Batch: 3680/40000 (9%) | Loss: 0.538850
Epoch: 1 | Batch: 3840/40000 (10%) | Loss: 0.389673
Epoch: 1 | Batch: 4000/40000 (10%) | Loss: 0.414094
Epoch: 1 | Batch: 4160/40000 (10%) | Loss: 0.455343
Epoch: 1 | Batch: 4320/40000 (11%) | Loss: 0.480845
Epoch: 1 | Batch: 4480/40000 (11%) | Loss: 0.497369
Epoch: 1 | Batch: 4640/40000 (12%) | Loss: 0.495801
Epoch: 1 | Batch: 4800/40000 (12%) | Loss: 0.762025
Epoch: 1 | Batch: 4960/40000 (12%) | Loss: 0.411035
Epoch: 1 | Batch: 5120/40000 (13%) | Loss: 0.625638
Epoch: 1 | Batch: 5280/40000 (13%) | Loss: 0.661662
Epoch: 1 | Batch: 5440/40000 (14%) | Loss: 0.644914
Epoch: 1 | Batch: 5600/40000 (14%) | Loss: 0.547879
Epoch: 1 | Batch: 5760/40000 (14%) | Loss: 0.340415
Epoch: 1 | Batch: 5920/40000 (15%) | Loss: 0.518207
Epoch: 1 | Batch: 6080/40000 (15%) | Loss: 0.452335
Epoch: 1 | Batch: 6240/40000 (16%) | Loss: 0.534830
Epoch: 1 | Batch: 6400/40000 (16%) | Loss: 0.515209
Epoch: 1 | Batch: 6560/40000 (16%) | Loss: 0.429583
Epoch: 1 | Batch: 6720/40000 (17%) | Loss: 0.542565
Epoch: 1 | Batch: 6880/40000 (17%) | Loss: 0.633527
Epoch: 1 | Batch: 7040/40000 (18%) | Loss: 0.554004
Epoch: 1 | Batch: 7200/40000 (18%) | Loss: 0.413553
Epoch: 1 | Batch: 7360/40000 (18%) | Loss: 0.362603
Epoch: 1 | Batch: 7520/40000 (19%) | Loss: 0.491810
Epoch: 1 | Batch: 7680/40000 (19%) | Loss: 0.883693
Epoch: 1 | Batch: 7840/40000 (20%) | Loss: 0.255447
Epoch: 1 | Batch: 8000/40000 (20%) | Loss: 0.341620
Epoch: 1 | Batch: 8160/40000 (20%) | Loss: 0.389205
Epoch: 1 | Batch: 8320/40000 (21%) | Loss: 0.541028
Epoch: 1 | Batch: 8480/40000 (21%) | Loss: 0.393495
Epoch: 1 | Batch: 8640/40000 (22%) | Loss: 0.562666
Epoch: 1 | Batch: 8800/40000 (22%) | Loss: 0.564581
Epoch: 1 | Batch: 8960/40000 (22%) | Loss: 0.477882
Epoch: 1 | Batch: 9120/40000 (23%) | Loss: 0.525882
Epoch: 1 | Batch: 9280/40000 (23%) | Loss: 0.404535
Epoch: 1 | Batch: 9440/40000 (24%) | Loss: 0.259434
Epoch: 1 | Batch: 9600/40000 (24%) | Loss: 0.379545
Epoch: 1 | Batch: 9760/40000 (24%) | Loss: 0.715793
Epoch: 1 | Batch: 9920/40000 (25%) | Loss: 0.543178
Epoch: 1 | Batch: 10080/40000 (25%) | Loss: 0.402637
Epoch: 1 | Batch: 10240/40000 (26%) | Loss: 0.256205
Epoch: 1 | Batch: 10400/40000 (26%) | Loss: 0.950580
Epoch: 1 | Batch: 10560/40000 (26%) | Loss: 0.431973
Epoch: 1 | Batch: 10720/40000 (27%) | Loss: 0.500171
Epoch: 1 | Batch: 10880/40000 (27%) | Loss: 0.421861
Epoch: 1 | Batch: 11040/40000 (28%) | Loss: 0.305885
Epoch: 1 | Batch: 11200/40000 (28%) | Loss: 0.432073
Epoch: 1 | Batch: 11360/40000 (28%) | Loss: 0.446300
Epoch: 1 | Batch: 11520/40000 (29%) | Loss: 0.531358
Epoch: 1 | Batch: 11680/40000 (29%) | Loss: 0.423354
Epoch: 1 | Batch: 11840/40000 (30%) | Loss: 0.458235
Epoch: 1 | Batch: 12000/40000 (30%) | Loss: 0.666152
Epoch: 1 | Batch: 12160/40000 (30%) | Loss: 0.416585
Epoch: 1 | Batch: 12320/40000 (31%) | Loss: 0.444497
Epoch: 1 | Batch: 12480/40000 (31%) | Loss: 0.744255
Epoch: 1 | Batch: 12640/40000 (32%) | Loss: 0.418285
Epoch: 1 | Batch: 12800/40000 (32%) | Loss: 0.416661
Epoch: 1 | Batch: 12960/40000 (32%) | Loss: 0.343117
Epoch: 1 | Batch: 13120/40000 (33%) | Loss: 0.316724
Epoch: 1 | Batch: 13280/40000 (33%) | Loss: 0.414992
Epoch: 1 | Batch: 13440/40000 (34%) | Loss: 0.534303
Epoch: 1 | Batch: 13600/40000 (34%) | Loss: 0.505633
Epoch: 1 | Batch: 13760/40000 (34%) | Loss: 0.540524
Epoch: 1 | Batch: 13920/40000 (35%) | Loss: 0.424438
Epoch: 1 | Batch: 14080/40000 (35%) | Loss: 0.493455
Epoch: 1 | Batch: 14240/40000 (36%) | Loss: 0.561931
Epoch: 1 | Batch: 14400/40000 (36%) | Loss: 0.549122
Epoch: 1 | Batch: 14560/40000 (36%) | Loss: 0.712761
Epoch: 1 | Batch: 14720/40000 (37%) | Loss: 0.219853
Epoch: 1 | Batch: 14880/40000 (37%) | Loss: 0.384213
Epoch: 1 | Batch: 15040/40000 (38%) | Loss: 0.257454
Epoch: 1 | Batch: 15200/40000 (38%) | Loss: 0.471055
Epoch: 1 | Batch: 15360/40000 (38%) | Loss: 0.449118
Epoch: 1 | Batch: 15520/40000 (39%) | Loss: 0.672540
Epoch: 1 | Batch: 15680/40000 (39%) | Loss: 0.367258
Epoch: 1 | Batch: 15840/40000 (40%) | Loss: 0.712541
Epoch: 1 | Batch: 16000/40000 (40%) | Loss: 0.237277
Epoch: 1 | Batch: 16160/40000 (40%) | Loss: 0.789829
Epoch: 1 | Batch: 16320/40000 (41%) | Loss: 0.299161
Epoch: 1 | Batch: 16480/40000 (41%) | Loss: 0.748671
Epoch: 1 | Batch: 16640/40000 (42%) | Loss: 0.233250
Epoch: 1 | Batch: 16800/40000 (42%) | Loss: 0.907594
Epoch: 1 | Batch: 16960/40000 (42%) | Loss: 0.579401
Epoch: 1 | Batch: 17120/40000 (43%) | Loss: 0.251984
Epoch: 1 | Batch: 17280/40000 (43%) | Loss: 0.291636
Epoch: 1 | Batch: 17440/40000 (44%) | Loss: 0.657922
Epoch: 1 | Batch: 17600/40000 (44%) | Loss: 0.556189
Epoch: 1 | Batch: 17760/40000 (44%) | Loss: 0.298073
Epoch: 1 | Batch: 17920/40000 (45%) | Loss: 0.371886
Epoch: 1 | Batch: 18080/40000 (45%) | Loss: 0.755608
Epoch: 1 | Batch: 18240/40000 (46%) | Loss: 0.555657
Epoch: 1 | Batch: 18400/40000 (46%) | Loss: 0.514049
Epoch: 1 | Batch: 18560/40000 (46%) | Loss: 0.421416
Epoch: 1 | Batch: 18720/40000 (47%) | Loss: 0.372952
Epoch: 1 | Batch: 18880/40000 (47%) | Loss: 0.357475
Epoch: 1 | Batch: 19040/40000 (48%) | Loss: 0.441757
Epoch: 1 | Batch: 19200/40000 (48%) | Loss: 0.645867
Epoch: 1 | Batch: 19360/40000 (48%) | Loss: 0.653929
Epoch: 1 | Batch: 19520/40000 (49%) | Loss: 0.441530
Epoch: 1 | Batch: 19680/40000 (49%) | Loss: 0.554113
Epoch: 1 | Batch: 19840/40000 (50%) | Loss: 0.310708
Epoch: 1 | Batch: 20000/40000 (50%) | Loss: 0.538493
Epoch: 1 | Batch: 20160/40000 (50%) | Loss: 0.234916
Epoch: 1 | Batch: 20320/40000 (51%) | Loss: 0.469252
Epoch: 1 | Batch: 20480/40000 (51%) | Loss: 0.213102
Epoch: 1 | Batch: 20640/40000 (52%) | Loss: 0.507701
Epoch: 1 | Batch: 20800/40000 (52%) | Loss: 0.401435
Epoch: 1 | Batch: 20960/40000 (52%) | Loss: 0.496054
Epoch: 1 | Batch: 21120/40000 (53%) | Loss: 0.291521
Epoch: 1 | Batch: 21280/40000 (53%) | Loss: 0.397672
Epoch: 1 | Batch: 21440/40000 (54%) | Loss: 0.543521
Epoch: 1 | Batch: 21600/40000 (54%) | Loss: 0.338761
Epoch: 1 | Batch: 21760/40000 (54%) | Loss: 0.546071
Epoch: 1 | Batch: 21920/40000 (55%) | Loss: 0.337996
Epoch: 1 | Batch: 22080/40000 (55%) | Loss: 0.282862
Epoch: 1 | Batch: 22240/40000 (56%) | Loss: 0.745219
Epoch: 1 | Batch: 22400/40000 (56%) | Loss: 0.373264
Epoch: 1 | Batch: 22560/40000 (56%) | Loss: 0.453183
Epoch: 1 | Batch: 22720/40000 (57%) | Loss: 0.459756
Epoch: 1 | Batch: 22880/40000 (57%) | Loss: 0.341929
Epoch: 1 | Batch: 23040/40000 (58%) | Loss: 0.261242
Epoch: 1 | Batch: 23200/40000 (58%) | Loss: 0.842183
Epoch: 1 | Batch: 23360/40000 (58%) | Loss: 0.461603
Epoch: 1 | Batch: 23520/40000 (59%) | Loss: 0.366011
Epoch: 1 | Batch: 23680/40000 (59%) | Loss: 0.337995
Epoch: 1 | Batch: 23840/40000 (60%) | Loss: 0.338164
Epoch: 1 | Batch: 24000/40000 (60%) | Loss: 0.473866
Epoch: 1 | Batch: 24160/40000 (60%) | Loss: 0.421807
Epoch: 1 | Batch: 24320/40000 (61%) | Loss: 0.501308
Epoch: 1 | Batch: 24480/40000 (61%) | Loss: 0.524940
Epoch: 1 | Batch: 24640/40000 (62%) | Loss: 0.484799
Epoch: 1 | Batch: 24800/40000 (62%) | Loss: 0.458384slurmstepd: error: *** JOB 61576 ON c227-115 CANCELLED AT 2019-11-23T15:17:57 ***
